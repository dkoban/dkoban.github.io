---
title: |
  <center>Comparison of Botometer vs. BotometerLite Bot Detection Scores</center>
output:
  html_document:
    toc: true
    toc_float:
      toc_collapsed: true
    theme: lumen
bibliography: citations.bib
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
```

<style type="text/css">
.main-container {
  max-width: 1800px;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r}
library(knitr)
library(tidyverse)
library(ggplot2)
require(plyr)
```


<div style="margin-left: 50px; margin-right:50px;">
**Abstract:** BotometerLite is advertised as a lightweight bot detector that improves scalability by focusing on only user profile information; furthermore, BotometerLite claims that using fewer features only entails a small compromise in individual accuracy. We test the validity of this claim by comparing Botometer with BotometerLite bot likelihood scores for 75,000 users across 5 data sets. We randomly sampled 15,000 users from the following data sets: Coronavirus, 2016 election, News outlets, Charlottesville, and the Twitter API. BotometerLite scores varied drastically from Botometer scores.   
</div> 

## Introduction

Botometer is one of the most popular bot detection tools used in social science @rauchfleisch2020false. However, due to Botometer API rate limits, @beskow2018introducing recommends a tiered framework for bot detection and suggests models that focus only on user profile information can be used at scale for general estimates of bot penetration.

@yuan2019examining used DeBot for large-scale bot annotations when examining tweets related to the 2015 California Disneyland measles outbreak. Whereas, @broniatowski2016effective used Botometer for small-scale bot annotations. 

@dunn2020limited annotated bots based on Botometer scores of 0.5 of greater when assessing the limited role of bots in spreading vaccine-critical information.  Botometer's [FAQ page](https://botometer.osome.iu.edu/faq) explicitly states "It's tempting to set some arbitrary threshold score and consider everything above that number a bot and everything below a human, but we do not recommend this approach. Binary classification of accounts using two classes is problematic because few accounts are completely automated".  Instead, Botometer recommends setting a threshold on the CAP score.  @dunn2020limited acknowledges the imprecision inherent in bot detection and states the conclusions of this study are robust to differences related to imprecision of the bot proportion estimate.  

Botometer was initially launched in May 2014 and BotometerLite was released in September 2020. BotometerLite improves scalability by focusing on only user profile information; furthermore, BotometerLite claims that using fewer features only entails a small compromise in individual accuracy @yang2020scalable. The training and performance evaluation of BotometerLite is described in "Scalable and Generalizable Social Bot Detection through Data Selection" @yang2020scalable. 

@rauchfleisch2020false found Botometer scores are imprecise at estimating bots, especially in a different language, and prone to variance over time a high number of human users as bots and vice versa. 

### Contribution

Many researchers annotate bots based on Botometer score thresholds, in line with the precedent established in previous literature (add citations). Understanding how BotometerLite performs in comparison to Botometer is critical to prevent people from thinking BotometerLite can be used as a scalable substitute for Botometer.

### Research Questions

In this study, we seek to answer the following questions: 

- How similar are Botometer and BotometerLite ratings? 
- Is BotometerLite effective at identifying specific types of bots? In other words, are BotometerLite scores strongly correlated with any of the Botometer category scores (e.g., spammers, fake followers, etc.)?
- Can BotometerLite be used as an triage tool to identify a subset of accounts that require more extensive evaluation via Botometer?
- Do some topics have more assessed bots than others?  How do the topic-specific bot category scores compare to a random sample of twitter users?

### Bot Type Scores

The Botometer [FAQ](https://botometer.osome.iu.edu/faq) section assigns bot scores based on the following categories:

- **Astroturf:** manually labeled political bots and accounts involved in follow trains that systematically delete content
- **Fake follower:** bots purchased to increase follower counts
- **Financial:** bots that post using cashtags
- **Self declared:** bots from botwiki.org
- **Spammer:** accounts labeled as spambots from several datasets
- **Other:** miscellaneous other bots obtained from manual annotation, user feedback, etc.

**Complete Automation Probability** is defined as the probability, according to our models, that an account with this score or greater is a bot. 

The Botometer website uses the CAP to express the percentage of accounts with bot score above a given account that are labeled as humans. Think of this as the chances that you would wrongly classify a human as a bot if you used this account's score as a threshold. You would want this probability to be pretty small, say less than 5%. (For the statisticians, this is a p-value.)

## Methodology

1. Randomly sample 20,000 tweet IDs from GWU's [Tweet Sets Library]( https://tweetsets.library.gwu.edu/datasets) in the following collections:
    - [Coronavirus](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/LW0BTB): collected March 3 2020 to June 9, 2020 
    - [2016 election](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/PDI7IN): collected July 13, 2016 to November 10, 2016
    - [News outlets](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/2FIFLH): collected August 4, 2016 to May 12, 2020
    - [Charlottesville](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DVLJTO): August, 2017
    - Random sample drawn from twitter API on November 1st (_*2 days before Presidential Election*_)
2. Rehydrate the tweet IDs via Twarc to obtain user IDs.
3. Randomly sample 12,000 unique user IDs from the 20,000 tweets (some users are duplicated in the initial 15K sample).
4. Enrich 10,000 user IDs with Botometer scores (not all users will return a Botometer score)
5. Enrich with BotometerLite scores 
6. **Filter tweet IDs to only those with an English status language.**
7. Compare distribution of CAP scores across data sets.
8. Compare proportion of bot category scores > k across data sets (e.g., how many accounts had astroturf scores greater than k in each data set? did one data set have siginificantly more than others?)
9. Calculate correlation between Botometer and BotometerLite scores.

## Results

The following preliminary results explore the similarity between Botometer and BotometerLite scores for users from the Coronavirus and 5G data sets, as well as a random sample of tweets collected on 1 November 2020. 

### Bot Proportions by Type

The table below shows the number of accounts with raw English scores greater than $k = 0.75$.  In this example, I did not exclude accounts with non-English status languages.

```{r}
calc_bot_prop <- function(df, k){
df <- data_frame(
  "astro" = sum(df$astroturf_raw_en >= k),
  "fake" = sum(df$fake_follower_raw_en >= k),
  "spammer" = sum(df$spammer_raw_en >= k),
  "finance" = sum(df$financial_raw_en >= k),
  "self_declared" = sum(df$self_declared_raw_en >= k),
  "other" = sum(df$other_raw_en >= k),
  "overall" = sum(df$overall_raw_en >= k),
  "cap" = sum(df$cap_en >= k),
  "bot_lite" = sum(df$bot_lite >= k))
return(df)
}

k = 0.5
corona <- read_csv("~/Documents/EM6574/covid_bot_scores_1Nov2020.csv") %>%
  mutate(id_str = id_str %>% as.character())
corona_lang <- read_csv("~/Documents/EM6574/lang_id_covid.csv") %>%
  mutate(id_str = id_str %>% as.character()) %>% distinct(id_str, status_lang)
corona_bot_prop <- calc_bot_prop(corona, k = k)

random <- read_csv("~/Documents/EM6574/random_bot_scores_2Nov2020.csv") %>%
  mutate(id_str = id_str %>% as.character())

# files = list.files("~/Documents/EM6574/output_files")
# df_list <- list()
# for (i in 1:length(files)){
#   df_list[[i]] <- read_csv(paste0("~/Documents/EM6574/output_files/", files[i]),
#                            col_types = cols(screen_name = col_character()))
# }
# random <- bind_rows(df_list) %>% mutate(bot_lite = 1, 
#                                         id_str = id_str %>% as.character()) 
random_bot_prop <- calc_bot_prop(random, k = k)

fiveg0 <- read_csv("~/Documents/EM6574/botometer_full_5G.csv") %>%
  mutate(id_str = id_str %>% as.character())
fiveg1 <- read_csv("~/Documents/EM6574/botometer_scores_20Oct2020.csv") %>%
  dplyr::select(id_str = user_id, bot_lite = botscore) %>%
  mutate(id_str = id_str %>% as.character())
fiveg <- fiveg0 %>% left_join(fiveg1, by = "id_str") %>%
  filter(!is.na(bot_lite))
fiveg_bot_prop <- calc_bot_prop(fiveg, k = k)

format_counts <- function(count, tot){
  return(paste0(count, " (", round(count/tot,2), ")"))
}

#library(DT)
cat_tbl <- data_frame(
  "Category" = c("Sample Size", "Astroturf", "Fake Follower", "Spammer", "Financial", 
                 "Self Declared", "Other", "Overall", "CAP", "BotometerLite"),
  "Coronavirus" = c(nrow(corona),
                    paste0("<b>", format_counts(corona_bot_prop$astro, nrow(corona)),
                           "</b>"),
                    format_counts(corona_bot_prop$fake, nrow(corona)),
                    format_counts(corona_bot_prop$spammer, nrow(corona)),
                    format_counts(corona_bot_prop$finance, nrow(corona)),
                    format_counts(corona_bot_prop$self_declared, nrow(corona)),
                    format_counts(corona_bot_prop$other, nrow(corona)),
                    format_counts(corona_bot_prop$overall, nrow(corona)),
                    format_counts(corona_bot_prop$cap, nrow(corona)),
                    format_counts(corona_bot_prop$bot_lite, nrow(corona))),
  "Election 2016" = c("-", "-", "-", "-", "-", "-", "-", "-", "-", "-"),
  "News Outlets" = c("-", "-", "-", "-", "-", "-", "-", "-", "-", "-"),
  "Charlottesville" = c("-", "-", "-", "-", "-", "-", "-", "-", "-", "-"),
  "5G" = c(nrow(fiveg),
           format_counts(fiveg_bot_prop$astro, nrow(fiveg)),
           format_counts(fiveg_bot_prop$fake, nrow(fiveg)),
           format_counts(fiveg_bot_prop$spammer, nrow(fiveg)),
           format_counts(fiveg_bot_prop$finance, nrow(fiveg)),
           format_counts(fiveg_bot_prop$self_declared, nrow(fiveg)),
           format_counts(fiveg_bot_prop$other, nrow(fiveg)),
           format_counts(fiveg_bot_prop$overall, nrow(fiveg)),
           format_counts(fiveg_bot_prop$cap, nrow(fiveg)),
           format_counts(fiveg_bot_prop$bot_lite, nrow(fiveg))),
  "Random" = c(nrow(random),
               format_counts(random_bot_prop$astro, nrow(random)),
               paste0("<b>", format_counts(random_bot_prop$fake, nrow(random)),
                      "</b>"),
               format_counts(random_bot_prop$spammer, nrow(random)),
               format_counts(random_bot_prop$finance, nrow(random)),
               paste0("<b>", format_counts(random_bot_prop$self_declared, nrow(random)),
                      "</b>"),
               format_counts(random_bot_prop$other, nrow(random)),
               format_counts(random_bot_prop$overall, nrow(random)),
               format_counts(random_bot_prop$cap, nrow(random)),
               format_counts(random_bot_prop$bot_lite, nrow(random))))
#datatable(cat_tbl, filter = "none")
kable(cat_tbl)
```

The table below shows the number of english accounts with raw English scores greater than $k = 0.75$. In this example, I only included accounts with an English status language.  Applying English bot detection metrics to non-English users resulted increased bot detections.  Therefore, users must be careful to filter on status language to prevent inflating bot counts.   

```{r}
calc_bot_prop <- function(df, k){
df <- data_frame(
  "astro" = sum(df$astroturf_raw_en >= k),
  "fake" = sum(df$fake_follower_raw_en >= k),
  "spammer" = sum(df$spammer_raw_en >= k),
  "finance" = sum(df$financial_raw_en >= k),
  "self_declared" = sum(df$self_declared_raw_en >= k),
  "other" = sum(df$other_raw_en >= k),
  "overall" = sum(df$overall_raw_en >= k),
  "cap" = sum(df$cap_en >= k),
  "bot_lite" = sum(df$bot_lite >= k))
return(df)
}

k = 0.5
corona <- read_csv("~/Documents/EM6574/covid_bot_scores_1Nov2020.csv") %>%
  mutate(id_str = id_str %>% as.character())
corona_lang <- read_csv("~/Documents/EM6574/lang_id_covid.csv") %>%
  mutate(id_str = id_str %>% as.character()) %>% distinct(id_str, status_lang)
corona_lang <- corona_lang%>%
  dplyr::group_by(id_str) %>% 
  dplyr::summarise(count = n(), 
                   status_lang = paste0(status_lang %>% unique(), collapse = ", "))
corona <- corona %>% left_join(corona_lang, by = 'id_str') %>%
  dplyr::filter(status_lang == 'en')
corona_bot_prop <- calc_bot_prop(corona, k = k)

random <- read_csv("~/Documents/EM6574/random_bot_scores_2Nov2020.csv") %>%
  mutate(id_str = id_str %>% as.character())
random_lang <- read_csv("~/Documents/EM6574/lang_id_random.csv") %>%
  mutate(id_str = id_str %>% as.character()) %>% distinct(id_str, status_lang)
random_lang <- random_lang%>%
  dplyr::group_by(id_str) %>% 
  dplyr::summarise(count = n(), 
                   status_lang = paste0(status_lang %>% unique(), collapse = ", "))
random <- random %>% left_join(random_lang, by = 'id_str') %>%
  dplyr::filter(status_lang == 'en')
random_bot_prop <- calc_bot_prop(random, k = k)

fiveg0 <- read_csv("~/Documents/EM6574/botometer_full_5G.csv") %>%
  mutate(id_str = id_str %>% as.character())
fiveg1 <- read_csv("~/Documents/EM6574/botometer_scores_20Oct2020.csv") %>%
  dplyr::select(id_str = user_id, bot_lite = botscore) %>%
  mutate(id_str = id_str %>% as.character())
fiveg <- fiveg0 %>% left_join(fiveg1, by = "id_str") %>%
  filter(!is.na(bot_lite))
fiveg_bot_prop <- calc_bot_prop(fiveg, k = k)

format_counts <- function(count, tot){
  return(paste0(count, " (", round(count/tot,2), ")"))
}

#library(DT)
cat_tbl <- data_frame(
  "Category" = c("Sample Size", "Astroturf", "Fake Follower", "Spammer", "Financial", 
                 "Self Declared", "Other", "Overall", "CAP", "BotometerLite"),
  "Coronavirus" = c(nrow(corona),
                    paste0("<b>", format_counts(corona_bot_prop$astro, nrow(corona)),
                           "</b>"),
                    format_counts(corona_bot_prop$fake, nrow(corona)),
                    format_counts(corona_bot_prop$spammer, nrow(corona)),
                    format_counts(corona_bot_prop$finance, nrow(corona)),
                    format_counts(corona_bot_prop$self_declared, nrow(corona)),
                    format_counts(corona_bot_prop$other, nrow(corona)),
                    format_counts(corona_bot_prop$overall, nrow(corona)),
                    format_counts(corona_bot_prop$cap, nrow(corona)),
                    format_counts(corona_bot_prop$bot_lite, nrow(corona))),
  "Election 2016" = c("-", "-", "-", "-", "-", "-", "-", "-", "-", "-"),
  "News Outlets" = c("-", "-", "-", "-", "-", "-", "-", "-", "-", "-"),
  "Charlottesville" = c("-", "-", "-", "-", "-", "-", "-", "-", "-", "-"),
  "5G" = c(nrow(fiveg),
           format_counts(fiveg_bot_prop$astro, nrow(fiveg)),
           format_counts(fiveg_bot_prop$fake, nrow(fiveg)),
           format_counts(fiveg_bot_prop$spammer, nrow(fiveg)),
           format_counts(fiveg_bot_prop$finance, nrow(fiveg)),
           format_counts(fiveg_bot_prop$self_declared, nrow(fiveg)),
           format_counts(fiveg_bot_prop$other, nrow(fiveg)),
           format_counts(fiveg_bot_prop$overall, nrow(fiveg)),
           format_counts(fiveg_bot_prop$cap, nrow(fiveg)),
           format_counts(fiveg_bot_prop$bot_lite, nrow(fiveg))),
  "Random" = c(nrow(random),
               format_counts(random_bot_prop$astro, nrow(random)),
               paste0("<b>", format_counts(random_bot_prop$fake, nrow(random)),
                      "</b>"),
               format_counts(random_bot_prop$spammer, nrow(random)),
               format_counts(random_bot_prop$finance, nrow(random)),
               paste0("<b>", format_counts(random_bot_prop$self_declared, nrow(random)),
                      "</b>"),
               format_counts(random_bot_prop$other, nrow(random)),
               format_counts(random_bot_prop$overall, nrow(random)),
               format_counts(random_bot_prop$cap, nrow(random)),
               format_counts(random_bot_prop$bot_lite, nrow(random))))
#datatable(cat_tbl, filter = "none")
kable(cat_tbl)
```


### Botometer Score Distributions

```{r, fig.width=14, fig.height=4}
plot_exp_hist <- function(x, title){
  h <- hist(x, breaks = 10, 
            col = "lightgray", xlab = "Raw Score", 
            main = title) 
  xfit <- seq(min(x), max(x), length = 40) 
  yfit <- dexp(xfit, rate = 1/mean(x)) 
  yfit <- yfit * diff(h$mids[1:2]) * length(x) 
  lines(xfit, yfit, col = "blue", lwd = 2)}

plot_norm_hist <- function(x, title, y_max, breaks){
  h <- hist(x, breaks = breaks, ylim = c(0, y_max),
            col = "lightgray", xlab = "Raw Score", 
            main = title) 
  xfit <- seq(min(x), max(x), length = 40) 
  yfit <- dnorm(xfit, mean = mean(x), sd = sd(x)) 
  yfit <- yfit * diff(h$mids[1:2]) * length(x) 
  lines(xfit, yfit, col = "blue", lwd = 2)}

par(mfrow=c(1,3),oma = c(0, 0, 2, 0))
plot_exp_hist(x= corona$astroturf_raw_en, title = 'Coronavirus')
plot_exp_hist(x= fiveg$astroturf_raw_en, title = '5G')
plot_exp_hist(x= random$astroturf_raw_en, title = 'Random')
mtext("Astroturf Raw Score Distribution", 
      side = 3, line = 0, outer = TRUE, cex=1.5,font=2)
```


```{r, fig.width=14, fig.height=4}
par(mfrow=c(1,3),oma = c(0, 0, 2, 0))
plot_exp_hist(x= corona$fake_follower_raw_en, title = 'Coronavirus')
plot_exp_hist(x= fiveg$fake_follower_raw_en, title = '5G')
plot_exp_hist(x= random$fake_follower_raw_en, title = 'Random')
mtext("Fake Follower Raw Score Distribution", 
      side = 3, line = 0, outer = TRUE, cex=1.5,font=2)
```

```{r, fig.width=14, fig.height=4}
par(mfrow=c(1,3),oma = c(0, 0, 2, 0))
plot_exp_hist(x= corona$financial_raw_en, title = 'Coronavirus')
plot_exp_hist(x= fiveg$financial_raw_en, title = '5G')
plot_exp_hist(x= random$financial_raw_en, title = 'Random')
mtext("Financial Raw Score Distribution", 
      side = 3, line = 0, outer = TRUE, cex=1.5,font=2)
```

```{r, fig.width=14, fig.height=4}
par(mfrow=c(1,3),oma = c(0, 0, 2, 0))
plot_exp_hist(x= corona$self_declared_raw_en, title = 'Coronavirus')
plot_exp_hist(x= fiveg$self_declared_raw_en, title = '5G')
plot_exp_hist(x= random$self_declared_raw_en, title = 'Random')
mtext("Self Declared Score Distribution", 
      side = 3, line = 0, outer = TRUE, cex=1.5,font=2)
```

```{r, fig.width=14, fig.height=4}
par(mfrow=c(1,3),oma = c(0, 0, 2, 0))
hist(x= corona$other_raw_en, main = 'Coronavirus')
hist(x= fiveg$other_raw_en, main = '5G')
hist(x= random$other_raw_en, main = 'Random')
mtext("Other Score Distribution", 
      side = 3, line = 0, outer = TRUE, cex=1.5,font=2)
```

```{r, fig.width=14, fig.height=4}
par(mfrow=c(1,3),oma = c(0, 0, 2, 0))
hist(x= corona$overall_raw_en, main = 'Coronavirus')
hist(x= fiveg$overall_raw_en, main = '5G')
hist(x= random$overall_raw_en, main = 'Random')
mtext("Overall Score Distribution", 
      side = 3, line = 0, outer = TRUE, cex=1.5,font=2)
```

```{r, fig.width=14, fig.height=4}
par(mfrow=c(1,3),oma = c(0, 0, 2, 0))
hist(x= corona$cap_en, main = 'Coronavirus')
hist(x= fiveg$cap_en, main = '5G')
hist(x= random$cap_en, main = 'Random')
mtext("CAP Score Distribution", 
      side = 3, line = 0, outer = TRUE, cex=1.5,font=2)
```

```{r, fig.width=14, fig.height=4}
par(mfrow=c(1,3),oma = c(0, 0, 2, 0))
plot_exp_hist(x= corona$bot_lite, title = 'Coronavirus')
plot_exp_hist(x= fiveg$bot_lite, title = '5G')
plot_exp_hist(x= random$bot_lite, title = 'Random')
mtext("Botometer Lite Score Distribution", 
      side = 3, line = 0, outer = TRUE, cex=1.5,font=2)
```

### Raw Score Correlations

BotometerLite is most similar to the Botometer fake follower and spammer scores with $R^2$ values of 0.362 and 0.298, respectively.  Hence, if Botometer scores are accurate, BotometerLite may be somewhat effective at identifying some fake followers and spammers.

```{r, fig.width=14, fig.height=12}
all_data <- bind_rows(corona, fiveg, random)
all_data <- all_data[!is.na(all_data$cap_en),]
  
all_data_stack <- bind_rows(
  all_data %>% dplyr::select(id_str, screen_name, 
                       bot_full = astroturf_raw_en, bot_lite) %>%
    mutate(type = "Astroturf"),
  all_data %>% dplyr::select(id_str, screen_name, 
                       bot_full = fake_follower_raw_en, bot_lite) %>%
    mutate(type = "Fake Follower"),
  all_data %>% dplyr::select(id_str, screen_name, 
                       bot_full = financial_raw_en, bot_lite) %>%
    mutate(type = "Financial"),
  all_data %>% dplyr::select(id_str, screen_name, 
                       bot_full = spammer_raw_en, bot_lite) %>%
    mutate(type = "Spammer"),
  all_data %>% dplyr::select(id_str, screen_name, 
                       bot_full = self_declared_raw_en, bot_lite) %>%
    mutate(type = "Self Declared"),
  all_data %>% dplyr::select(id_str, screen_name,
                       bot_full = other_raw_en, bot_lite) %>%
    mutate(type = "Other"),
  all_data %>% dplyr::select(id_str, screen_name,
                       bot_full = overall_raw_en, bot_lite) %>%
    mutate(type = "Overall"),
  all_data %>% dplyr::select(id_str, screen_name,
                       bot_full = cap_en, bot_lite) %>%
    mutate(type = "Complete Automation Probability"))       

lm_eqn = function(df){
    m = lm(bot_full ~ bot_lite, df);
    eq <- substitute(italic(r)^2~"="~r2, 
         list(r2 = format(summary(m)$r.squared, digits = 3)))
    as.character(as.expression(eq));                 
}        

eq <- ddply(all_data_stack,.(type),lm_eqn)

ggplot(data = all_data_stack,
       mapping = aes(x = bot_lite,
                     y = bot_full)) +
  geom_point(size = 0.5, color = "blue", alpha = 0.5) +
   stat_smooth(method = "lm",color="red") +
  geom_label(data=eq,aes(x = 0.85, y = 0.9,label=V1), 
            parse = TRUE, inherit.aes=FALSE) +
  facet_wrap(~type, ncol = 3) +
  labs(title = "Botometer vs. BotometerLite Bot Likelihood Scores",
         x = "BotometerLite Score",
         y = "Botometer Score")
```

### Expected Bot Count by CAP

CAP is the probability that an account with this score or greater is a bot. Therefore, if we model an accounts bot status as a Poisson binomial random variable, the expected number of bots is given by:

<center>
$E[\sum x_{i}]=\sum p_{i}$
</center>

```{r, eval = TRUE}
all_data <- bind_rows(corona, fiveg, random)
all_data <- all_data[!is.na(all_data$cap_en), ]
#sum(all_data$cap_en[all_data$cap_en >= 0.75])/length(all_data$cap_en)
#length(all_data$cap_en)
#sum(all_data$cap_en)/length(all_data$cap_en)
#sum(all_data$cap_en)
```

<br>
Hence, we should expect `r sum(all_data$cap_en) %>% as.integer()` (`r round(100*sum(all_data$cap_en)/length(all_data$cap_en),1)`%) of the `r length(all_data$cap_en)` accounts to be bots. 

```{r}
cat_tbl <- data_frame(
  "Category" = c("Sum English CAP",
                 "Sum Universal CAP",
                 "English Overall k >= 0.75",
                 "Universal Overall k >= 0.75",
                 "BotometerLite k >= 0.75"),
  "Expected # of Bots" = c(paste0(round(sum(all_data$cap_en)), " (",
                           round(sum(all_data$cap_en)/nrow(all_data),2), ")"),
                           paste0(round(sum(all_data$cap_un)), " (",
                           round(sum(all_data$cap_un)/nrow(all_data),2), ")"),
                           format_counts(sum(all_data$overall_raw_en >= 0.75),
                                         nrow(all_data)),
                           format_counts(sum(all_data$overall_raw_un >= 0.75),
                                         nrow(all_data)),
                           format_counts(sum(all_data$bot_lite >= 0.75),
                                         nrow(all_data))))
kable(cat_tbl)
```

Expected bots by data set based on English CAP scores:

- Coronavirus: `r sum(corona$cap_en) %>% as.integer()` (`r round(100*sum(corona$cap_en)/length(corona$cap_en),1)`%) of `r length(corona$cap_en)` accounts.
- 5G: `r sum(fiveg$cap_en) %>% as.integer()` (`r round(100*sum(fiveg$cap_en)/length(fiveg$cap_en),1)`%) of `r length(fiveg$cap_en)` accounts.
- Random: `r sum(random$cap_en) %>% as.integer()` (`r round(100*sum(random$cap_en)/length(random$cap_en),1)`%) of `r length(random$cap_en)` accounts.

```{r, fig.width=14, fig.height=4}
par(mfrow=c(1,3),oma = c(0, 0, 2, 0))
hist(x= corona$cap_en, main = 'Coronavirus')
hist(x= fiveg$cap_en, main = '5G')
hist(x= random$cap_en, main = 'Random')
mtext("CAP Score Distribution", 
      side = 3, line = 0, outer = TRUE, cex=1.5,font=2)
```

### Profile Info of Suspected Bots

Users with overall bot scores >= 0.75.

```{r}
library(DT)
covid_user <- read_csv("~/Documents/EM6574/covid/covid_user_info.csv") %>%
  mutate(id_str = id_str %>% as.character())
covid_overall <- corona %>% dplyr::select(id_str, overall_raw_en, bot_lite) %>%
  dplyr::filter(overall_raw_en >= 0.75) %>%
  left_join(covid_user, by = "id_str") %>%
  dplyr::select(name, screen_name, 
                overall_raw_en, bot_lite,
                followers_count, friends_count, favourites_count, verified) %>%
  arrange(desc(overall_raw_en)) %>% distinct()
datatable(covid_overall)
```

Users with astroturf bot scores >= 0.75.

```{r}
library(DT)
covid_user <- read_csv("~/Documents/EM6574/covid/covid_user_info.csv") %>%
  mutate(id_str = id_str %>% as.character())
covid_astro <- corona %>% dplyr::select(id_str, astroturf_raw_en, bot_lite) %>%
  dplyr::filter(astroturf_raw_en >= 0.75) %>%
  left_join(covid_user, by = "id_str") %>%
  dplyr::select(name, screen_name, 
                astroturf_raw_en, bot_lite,
                followers_count, friends_count, favourites_count, verified) %>%
  arrange(desc(astroturf_raw_en)) %>% distinct()
datatable(covid_astro)
```



## Conclusion

Future work for course project:

- Update introduction to include other articles that have critiqued Botometer
- For EM6574 only, replicate results of Indiana University BotometerLite paper (Train a classifier to predict manually labeled bots and compare with BotometerLite)
- Post code to github repo

Questions:

- Should I expand this beyond Botometer and include a comparison of scores generated from other models (e.g., DeBot, BotSlayer, etc.)
- Has anyone used DeBot? I requested an API key but did not receive a response.
- Do I have "the right" number for each of my samples (10,000 users per data set)?  Is a random sample appropriate?
- I forgot to filter on english only tweets when rehydrating the coronavirus tweets and pulling the random sample.  Do I need to repull my data???  Can I cut my sample size down so I don't have to repull all the data?
- What statistical tests should we do to provide evidence Botometer and BotometerLite produce different results?  t-test for difference of means? F-test for difference of variance? Hotelling test across all bot scores?
- Should we look at just the scores derived from english-speaking accounts or also include the universal scores?
- What visualizations should we use?  tSNE separating accounts with CAP > 0.8 from those with CAP < 0.8? 


The pearson correlation matrix ($R^2$ values are the square of the values of this matrix) also shows the scores are weakly correlated.

<center>
#![](correlation_heat_map.png){width=600px}
</center>

## References

---
nocite: '@*'
---
